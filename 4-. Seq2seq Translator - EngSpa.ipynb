{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/translation.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dataset-load\" data-toc-modified-id=\"Dataset-load-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset load</a></span></li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Architecture</a></span><ul class=\"toc-item\"><li><span><a href=\"#Encoder\" data-toc-modified-id=\"Encoder-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Encoder</a></span></li><li><span><a href=\"#Decoder\" data-toc-modified-id=\"Decoder-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Decoder</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Train Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-the-weights\" data-toc-modified-id=\"Save-the-weights-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Save the weights</a></span></li><li><span><a href=\"#Load-the-weights,-if-you-close-the-application\" data-toc-modified-id=\"Load-the-weights,-if-you-close-the-application-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Load the weights, if you close the application</a></span></li><li><span><a href=\"#Inference-Setup\" data-toc-modified-id=\"Inference-Setup-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Inference Setup</a></span></li><li><span><a href=\"#Decode-sample-sequeces\" data-toc-modified-id=\"Decode-sample-sequeces-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Decode sample sequeces</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Dataset\" data-toc-modified-id=\"Train-Dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Train Dataset</a></span></li><li><span><a href=\"#Validation-Dataset\" data-toc-modified-id=\"Validation-Dataset-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Validation Dataset</a></span></li><li><span><a href=\"#Evaluating-with-new-text:\" data-toc-modified-id=\"Evaluating-with-new-text:-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Evaluating with new text:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset load\n",
    "http://www.manythings.org/anki/  (Download and unzip spa-eng.zip file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= pd.read_table('data/Translator/spa.txt', names=['eng', 'spa','other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122936, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.spa=lines.spa.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.spa=lines.spa.apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.spa=lines.spa.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.spa=lines.spa.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.spa=lines.spa.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines.spa = lines.spa.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45429</td>\n",
       "      <td>he likes to live in tokyo</td>\n",
       "      <td>START_ le gusta vivir en tokio _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40971</td>\n",
       "      <td>he insulted me in public</td>\n",
       "      <td>START_ él me insultó en público _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88752</td>\n",
       "      <td>ive drunk way too much coffee today</td>\n",
       "      <td>START_ he bebido demasiado café hoy _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23275</td>\n",
       "      <td>who are those women</td>\n",
       "      <td>START_ ¿quiénes son esas mujeres _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86239</td>\n",
       "      <td>she died two days after his arrival</td>\n",
       "      <td>START_ ella murió dos días después de su llega...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>dont be evil</td>\n",
       "      <td>START_ no seáis malas _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113578</td>\n",
       "      <td>please remove your shoes before entering the h...</td>\n",
       "      <td>START_ por favor quítese los zapatos antes de ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61041</td>\n",
       "      <td>tom is honest so i like him</td>\n",
       "      <td>START_ tom es honesto por eso me gusta _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83826</td>\n",
       "      <td>tom couldnt say anything publicly</td>\n",
       "      <td>START_ tom no podía decir nada en público _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88843</td>\n",
       "      <td>it shouldnt take me long to do that</td>\n",
       "      <td>START_ no debería llevarme mucho tiempo hacerl...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "45429                           he likes to live in tokyo   \n",
       "40971                            he insulted me in public   \n",
       "88752                 ive drunk way too much coffee today   \n",
       "23275                                 who are those women   \n",
       "86239                 she died two days after his arrival   \n",
       "4080                                         dont be evil   \n",
       "113578  please remove your shoes before entering the h...   \n",
       "61041                         tom is honest so i like him   \n",
       "83826                   tom couldnt say anything publicly   \n",
       "88843                 it shouldnt take me long to do that   \n",
       "\n",
       "                                                      spa  \\\n",
       "45429                 START_ le gusta vivir en tokio _END   \n",
       "40971                START_ él me insultó en público _END   \n",
       "88752            START_ he bebido demasiado café hoy _END   \n",
       "23275               START_ ¿quiénes son esas mujeres _END   \n",
       "86239   START_ ella murió dos días después de su llega...   \n",
       "4080                           START_ no seáis malas _END   \n",
       "113578  START_ por favor quítese los zapatos antes de ...   \n",
       "61041         START_ tom es honesto por eso me gusta _END   \n",
       "83826      START_ tom no podía decir nada en público _END   \n",
       "88843   START_ no debería llevarme mucho tiempo hacerl...   \n",
       "\n",
       "                                                    other  \n",
       "45429   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "40971   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "88752   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "23275   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "86239   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "4080    CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "113578  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "61041   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "83826   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "88843   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of French \n",
    "all_spa_words=set()\n",
    "for spa in lines.spa:\n",
    "    for word in spa.split():\n",
    "        if word not in all_spa_words:\n",
    "            all_spa_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in lines.spa:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13467, 27431)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_spa_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_spa_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>START_ ve _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>START_ vete _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>go</td>\n",
       "      <td>START_ vaya _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>go</td>\n",
       "      <td>START_ váyase _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>hi</td>\n",
       "      <td>START_ hola _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>run</td>\n",
       "      <td>START_ ¡corre _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>run</td>\n",
       "      <td>START_ ¡corran _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>run</td>\n",
       "      <td>START_ ¡corra _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>run</td>\n",
       "      <td>START_ ¡corred _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>run</td>\n",
       "      <td>START_ corred _END</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng                  spa                                              other\n",
       "0   go       START_ ve _END  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1   go     START_ vete _END  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2   go     START_ vaya _END  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3   go   START_ váyase _END  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4   hi     START_ hola _END  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "5  run   START_ ¡corre _END  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "6  run  START_ ¡corran _END  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "7  run   START_ ¡corra _END  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "8  run  START_ ¡corred _END  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "9  run   START_ corred _END  CC-BY 2.0 (France) Attribution: tatoeba.org #4..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110642,), (12294,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = lines.eng, lines.spa\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture \n",
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lmendizb\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 1.9431 - acc: 0.1953 - val_loss: 1.1522 - val_acc: 0.2284\n",
      "Epoch 2/50\n",
      "493/492 [==============================] - 188s 382ms/step - loss: 1.6869 - acc: 0.2455 - val_loss: 1.0683 - val_acc: 0.2665\n",
      "Epoch 3/50\n",
      "493/492 [==============================] - 188s 381ms/step - loss: 1.5581 - acc: 0.2922 - val_loss: 0.9886 - val_acc: 0.3174\n",
      "Epoch 4/50\n",
      "493/492 [==============================] - 188s 381ms/step - loss: 1.4486 - acc: 0.3302 - val_loss: 0.9258 - val_acc: 0.3457\n",
      "Epoch 5/50\n",
      "493/492 [==============================] - 188s 381ms/step - loss: 1.3682 - acc: 0.3576 - val_loss: 0.8843 - val_acc: 0.3691\n",
      "Epoch 6/50\n",
      "493/492 [==============================] - 188s 382ms/step - loss: 1.3036 - acc: 0.3809 - val_loss: 0.8497 - val_acc: 0.3916\n",
      "Epoch 7/50\n",
      "493/492 [==============================] - 188s 382ms/step - loss: 1.2504 - acc: 0.4027 - val_loss: 0.8185 - val_acc: 0.4091\n",
      "Epoch 8/50\n",
      "493/492 [==============================] - 188s 382ms/step - loss: 1.2060 - acc: 0.4219 - val_loss: 0.7892 - val_acc: 0.4253\n",
      "Epoch 9/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 1.1676 - acc: 0.4385 - val_loss: 0.7674 - val_acc: 0.4397\n",
      "Epoch 10/50\n",
      "493/492 [==============================] - 189s 382ms/step - loss: 1.1337 - acc: 0.4542 - val_loss: 0.7494 - val_acc: 0.4516\n",
      "Epoch 11/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 1.1035 - acc: 0.4689 - val_loss: 0.7333 - val_acc: 0.4619\n",
      "Epoch 12/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 1.0780 - acc: 0.4820 - val_loss: 0.7215 - val_acc: 0.4713\n",
      "Epoch 13/50\n",
      "493/492 [==============================] - 189s 382ms/step - loss: 1.0522 - acc: 0.4943 - val_loss: 0.7077 - val_acc: 0.4797\n",
      "Epoch 14/50\n",
      "493/492 [==============================] - 188s 382ms/step - loss: 1.0264 - acc: 0.5056 - val_loss: 0.6949 - val_acc: 0.4872\n",
      "Epoch 15/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 1.0047 - acc: 0.5162 - val_loss: 0.6875 - val_acc: 0.4961\n",
      "Epoch 16/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 0.9860 - acc: 0.5260 - val_loss: 0.6803 - val_acc: 0.5016\n",
      "Epoch 17/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.9692 - acc: 0.5352 - val_loss: 0.6740 - val_acc: 0.5085\n",
      "Epoch 18/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.9543 - acc: 0.5445 - val_loss: 0.6688 - val_acc: 0.5134\n",
      "Epoch 19/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 0.9413 - acc: 0.5531 - val_loss: 0.6617 - val_acc: 0.5191\n",
      "Epoch 20/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.9296 - acc: 0.5606 - val_loss: 0.6544 - val_acc: 0.5250\n",
      "Epoch 21/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.9187 - acc: 0.5677 - val_loss: 0.6465 - val_acc: 0.5292\n",
      "Epoch 22/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.9075 - acc: 0.5742 - val_loss: 0.6396 - val_acc: 0.5338\n",
      "Epoch 23/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.8962 - acc: 0.5805 - val_loss: 0.6341 - val_acc: 0.5374\n",
      "Epoch 24/50\n",
      "493/492 [==============================] - 190s 384ms/step - loss: 0.8861 - acc: 0.5865 - val_loss: 0.6295 - val_acc: 0.5394\n",
      "Epoch 25/50\n",
      "493/492 [==============================] - 190s 384ms/step - loss: 0.8773 - acc: 0.5921 - val_loss: 0.6254 - val_acc: 0.5420\n",
      "Epoch 26/50\n",
      "493/492 [==============================] - 189s 383ms/step - loss: 0.8694 - acc: 0.5976 - val_loss: 0.6207 - val_acc: 0.5448\n",
      "Epoch 27/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8616 - acc: 0.6022 - val_loss: 0.6153 - val_acc: 0.5476\n",
      "Epoch 28/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8529 - acc: 0.6068 - val_loss: 0.6098 - val_acc: 0.5498\n",
      "Epoch 29/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8455 - acc: 0.6115 - val_loss: 0.6073 - val_acc: 0.5519\n",
      "Epoch 30/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.8392 - acc: 0.6157 - val_loss: 0.6054 - val_acc: 0.5539\n",
      "Epoch 31/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8332 - acc: 0.6195 - val_loss: 0.6034 - val_acc: 0.5553\n",
      "Epoch 32/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.8274 - acc: 0.6235 - val_loss: 0.6019 - val_acc: 0.5570\n",
      "Epoch 33/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8218 - acc: 0.6270 - val_loss: 0.6003 - val_acc: 0.5578\n",
      "Epoch 34/50\n",
      "493/492 [==============================] - 190s 385ms/step - loss: 0.8163 - acc: 0.6302 - val_loss: 0.5987 - val_acc: 0.5591\n",
      "Epoch 35/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.8108 - acc: 0.6336 - val_loss: 0.5976 - val_acc: 0.5595\n",
      "Epoch 36/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.8048 - acc: 0.6364 - val_loss: 0.5966 - val_acc: 0.5600\n",
      "Epoch 37/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7974 - acc: 0.6388 - val_loss: 0.5947 - val_acc: 0.5604\n",
      "Epoch 38/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7891 - acc: 0.6414 - val_loss: 0.5933 - val_acc: 0.5623\n",
      "Epoch 39/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7830 - acc: 0.6443 - val_loss: 0.5930 - val_acc: 0.5629\n",
      "Epoch 40/50\n",
      "493/492 [==============================] - 189s 384ms/step - loss: 0.7792 - acc: 0.6471 - val_loss: 0.5917 - val_acc: 0.5637\n",
      "Epoch 41/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7760 - acc: 0.6496 - val_loss: 0.5906 - val_acc: 0.5636\n",
      "Epoch 42/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7733 - acc: 0.6520 - val_loss: 0.5894 - val_acc: 0.5641\n",
      "Epoch 43/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7702 - acc: 0.6539 - val_loss: 0.5884 - val_acc: 0.5643\n",
      "Epoch 44/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7673 - acc: 0.6561 - val_loss: 0.5874 - val_acc: 0.5646\n",
      "Epoch 45/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7644 - acc: 0.6579 - val_loss: 0.5883 - val_acc: 0.5655\n",
      "Epoch 46/50\n",
      "493/492 [==============================] - 191s 387ms/step - loss: 0.7615 - acc: 0.6599 - val_loss: 0.5878 - val_acc: 0.5653\n",
      "Epoch 47/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7585 - acc: 0.6618 - val_loss: 0.5882 - val_acc: 0.5661\n",
      "Epoch 48/50\n",
      "493/492 [==============================] - 191s 387ms/step - loss: 0.7554 - acc: 0.6636 - val_loss: 0.5887 - val_acc: 0.5664\n",
      "Epoch 49/50\n",
      "493/492 [==============================] - 190s 386ms/step - loss: 0.7523 - acc: 0.6653 - val_loss: 0.5894 - val_acc: 0.5666\n",
      "Epoch 50/50\n",
      "493/492 [==============================] - 191s 386ms/step - loss: 0.7492 - acc: 0.6669 - val_loss: 0.5901 - val_acc: 0.5666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f56d402d9e8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "#                    steps_per_epoch = train_samples/batch_size,\n",
    "#                    epochs=epochs,\n",
    "#                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "#                    validation_steps = val_samples/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the weights, if you close the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('data/Translator/nmt_weights_complete_eng_esp.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "       \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "## Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input English sentence: the baby needs its mother\n",
      "Actual Spanish Translation:  el bebé necesita a su madre \n",
      "Predicted Spanish Translation:  el bebé necesita que él está \n",
      "\n",
      "Input English sentence: you lost\n",
      "Actual Spanish Translation:  has perdido \n",
      "Predicted Spanish Translation:  tú te vayas \n",
      "\n",
      "Input English sentence: i am married\n",
      "Actual Spanish Translation:  estoy casada \n",
      "Predicted Spanish Translation:  estoy casado \n",
      "\n",
      "Input English sentence: it wasnt tom who left the water running\n",
      "Actual Spanish Translation:  no fue tom quien dejó la llave del agua abierta \n",
      "Predicted Spanish Translation:  no fue la gente que de ver a su madre estaba brome\n",
      "\n",
      "Input English sentence: i am happy to see you again\n",
      "Actual Spanish Translation:  estoy feliz de verte otra vez \n",
      "Predicted Spanish Translation:  estoy contento de verte de nuevo \n",
      "\n",
      "Input English sentence: tom was really glad to hear that mary hadnt been injured in the accident\n",
      "Actual Spanish Translation:  tom se alegró mucho de saber que mary no había sido herida en el accidente \n",
      "Predicted Spanish Translation:  tom estaba realmente realmente hubiera oído no d\n",
      "\n",
      "Input English sentence: toms room is messy\n",
      "Actual Spanish Translation:  la pieza de tom está desordenada \n",
      "Predicted Spanish Translation:  la habitación de tom está de la pena \n",
      "\n",
      "Input English sentence: theyre correct\n",
      "Actual Spanish Translation:  son correctos \n",
      "Predicted Spanish Translation:  son de ellos \n",
      "\n",
      "Input English sentence: tom avoided mary\n",
      "Actual Spanish Translation:  tom evitaba a maría \n",
      "Predicted Spanish Translation:  tom lo que mary \n",
      "\n",
      "Input English sentence: tom doesnt eat anything except the vegetables that he grows himself\n",
      "Actual Spanish Translation:  tom no come nada aparte de las verduras que él mismo cultiva \n",
      "Predicted Spanish Translation:  tom no es nada como si los domingos hizo nada lo\n"
     ]
    }
   ],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1\n",
    "for k in range(10):\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('\\nInput English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Spanish Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "    print('Predicted Spanish Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input English sentence: it was the perfect moment for a kiss\n",
      "Actual Spanish Translation:  fue el momento perfecto para un beso \n",
      "Predicted Spanish Translation:  fue el trabajo allí es fácil de un accidente \n",
      "\n",
      "Input English sentence: he had a lot to do with that project\n",
      "Actual Spanish Translation:  él tuvo mucho que ver con ese proyecto \n",
      "Predicted Spanish Translation:  él tuvo que hacer mucho tiempo en avión \n",
      "\n",
      "Input English sentence: i think i have a theory about that\n",
      "Actual Spanish Translation:  creo que tengo una teoría sobre eso \n",
      "Predicted Spanish Translation:  creo que tengo una reunión es un \n",
      "\n",
      "Input English sentence: they took him to the hospital for his fever\n",
      "Actual Spanish Translation:  ellos lo llevaron al hospital por su fiebre \n",
      "Predicted Spanish Translation:  ellos se lo hizo un trabajo a la cocina \n",
      "\n",
      "Input English sentence: i need you to help me\n",
      "Actual Spanish Translation:  necesito que me ayudes \n",
      "Predicted Spanish Translation:  necesito que me te necesito \n",
      "\n",
      "Input English sentence: i see tom\n",
      "Actual Spanish Translation:  veo a tom \n",
      "Predicted Spanish Translation:  veo a tom \n",
      "\n",
      "Input English sentence: get lost\n",
      "Actual Spanish Translation:  ¡largo \n",
      "Predicted Spanish Translation:  vino a menudo \n",
      "\n",
      "Input English sentence: this really is remarkable\n",
      "Actual Spanish Translation:  esto es realmente excepcional \n",
      "Predicted Spanish Translation:  esto es realmente bastante \n",
      "\n",
      "Input English sentence: most of the dutch in new amsterdam did not leave\n",
      "Actual Spanish Translation:  la mayoría de los holandeses en nueva amsterdam no se fueron \n",
      "Predicted Spanish Translation:  la mayoría de los de la nueva no se fueron a escr\n",
      "\n",
      "Input English sentence: does it offend you\n",
      "Actual Spanish Translation:  ¿te ofende \n",
      "Predicted Spanish Translation:  ¿te te ha ido \n"
     ]
    }
   ],
   "source": [
    "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1\n",
    "for k in range(10):\n",
    "    (input_seq, actual_output), _ = next(val_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('\\nInput English sentence:', X_test[k:k+1].values[0])\n",
    "    print('Actual Spanish Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "    print('Predicted Spanish Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating with new text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: who is your father\n",
      "Actual Spanish Translation: quien es tu padre\n",
      "Predicted Spanish Translation:  ¿quién es tu padre \n"
     ]
    }
   ],
   "source": [
    "inputText = ['who is your father']\n",
    "outputText = ['quien es tu padre']\n",
    "\n",
    "train_gen = generate_batch(inputText, outputText, batch_size=1)\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "print('Input English sentence:', inputText[0])\n",
    "print('Actual Spanish Translation:', outputText[0])\n",
    "print('Predicted Spanish Translation:', decoded_sentence[:-4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
